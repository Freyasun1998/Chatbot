<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <title>Group 23 - NLP</title>

  <!-- CSS only -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx" crossorigin="anonymous">
  <link href="/docs/5.2/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx" crossorigin="anonymous">

  <!-- Favicons -->

  <!-- Custom styles for this template -->
  <link href="css/styles.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

</head>

<body>

  <!-- Navbar -->
  <div class="container" style="max-width: 800px">
    <nav class="navbar mx-auto bg-light px-4 fixed-top">
      <a class="navbar-brand" href="index.html">Big Data and Cloud Computing - Final Project</a>
      <ul class="nav nav-pills justify-content-center">
        <li class="nav-item"><a class="nav-link" href="index.html#projectIntroduction" style="color: black">Project
            Introduction</a></li>
        <li class="nav-item"><a class="nav-link" href="index.html#aboutTeam" style="color: black">About the Team</a>
        </li>
        <li class="nav-item"><a class="nav-link" href="EDA.html" style="color: black">EDA</a></li>
        <li class="nav-item"><a class="nav-link" href="NLP.html" style="color: black">NLP</a></li>
      </ul>
    </nav>





    <br>
    <h2>Natural Language Processing</h2>
    <hr>
    <br>

    <h4>
      Summary
    </h4>
    <p>
      We construct sentiment and topic features from the Reddit posts, to reflect what people talk about and how they
      feel about the Russia-Ukraine Conflict event. From the topic modeling, we find the submissions are concentrated
      among
      major three topics about “military force”, “city riot”, and “sanctions”, while the comments are more balanced on
      different topics. From the sentiment analysis, as <b>Table 1</b> shows, we find people have more negative comments
      and
      submissions than the positive ones, and they also tend to give higher scores for negative posts. From our
      preliminary analysis, we do not find strong correlations between commodity returns and topics or sentiments. This
      is not unexpected due to returns notoriously have low signal-to-noise ratios, and it also suggests that we should
      have more
      flexible model to capture text information.
    </p>
    <div class="table-responsive">
      <table class="table table-bordered table-hover table-condensed">
        <tr>
          <td>Score Stats</td>
          <td>Counts</td>
          <td>Average</td>
          <td>Range</td>
          <td>IQR</td>
          <td>Std</td>
          <td>Skewness</td>
        </tr>
        <tr>
          <td>Positive Submissions</td>
          <td>66445</td>
          <td>296.23</td>
          <td>0~108426</td>
          <td>109</td>
          <td>1741.93</td>
          <td>22.05</td>
        </tr>
        <tr>
          <td>Negative Submissions</td>
          <td>192527</td>
          <td>313.31</td>
          <td>0~195763</td>
          <td>168</td>
          <td>1554.17</td>
          <td>29.21</td>
        </tr>
        <tr>
          <td>Positive Comments</td>
          <td>2375428</td>
          <td>9.51</td>
          <td>-618~8607</td>
          <td>5</td>
          <td>47.40</td>
          <td>33.37</td>
        </tr>
        <tr>
          <td>Negative Comments</td>
          <td>4144561</td>
          <td>10.87</td>
          <td>-657~9421</td>
          <td>6</td>
          <td>52.92</td>
          <td>33.31</td>
        </tr>
      </table>
    </div>
    <p style="font-weight: lighter; text-align: center;"><strong>TABLE 1</strong> Statistics
      of Sentiment Scores. <a
        href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Sentiment/Sentiment%20Summary%20Tables.ipynb">Visualization
        Code</a>.</p>
    <br>
    <br>
    <br>


    <hr>
    <h4>
      Data Cleaning
    </h4>

    <p>
      Our text data sets are the Reddit comments and submissions from January 1, 2022 to August 31, 2022, amounting to
      10,378,762 unique posts. For submission posts, "title" and "selftext" are concatenated. We leverage Apache
      Spark and Spark NLP to build the text processing pipeline. <b>Figure 2</b> plots our data processing flow. First,
      we used the pre-trained model
      “detect_language_375” provided by John Snow Labs, to detect the languages of each post and estimate the language
      proportion from 0 to 1. We include posts in Ukrainian, Russian, and English, and create three sub-datasets for
      each of them by selecting posts with an estimated proportion above 0.8 for that language. Secondly, we remove
      posts with “[removed]”, “[deleted]”, and “[deleted by user]”. Thirdly, we apply common natural language text
      cleaning procedures including 1) changing all words into lower case, lowercase; 2) removing numbers,
      punctuations,and stopwords; 3) lemmatizing each word to its single format, e.g. "words" to "word", "makes" to
      "make".
    </p>
    <div class="row py-4">
      <div class="col-md-12">
        <div class="card p-0" style="border: none">
          <img src="img/NLP/data_flow.png" class="card-img-top" alt="...">
          <div class="card-body">
            <p style="font-weight: lighter; text-align: center;"><strong>FIGURE 1 </strong>Data Pipeline. <a
                href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/tree/master/code/Data">Pipeline
                Code</a>.</p>
          </div>
        </div>
      </div>
    </div>
    <p>
      We collect the commodity futures' price data from investing.com. The data has the same date range as the Reddit
      data from January 1, 2022 to August 31, 2022, covering 15 major food and energy commodities. To calculate the
      returns, we use daily close-to-close prices.
    </p>

    <br>
    <hr>
    <h4>Q1. (NLP) What are the major topics discussed in Reddit related to Russia Ukraine conflict?</h4>
    <br>
    <p>
      <strong>Topic models</strong> generate interpretable text features extracted from documents. These models help
      identify and cluster similar documents and are useful tools to tag documents.
    </p>

    <p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.LDA.html">Spark
        MLlib documentation</a> specifies the terminology used in this analysis: Link</p>
    <ol>
      <li><strong>term = word</strong>: an element of the vocabulary</li>
      <li><strong>token</strong>: instance of a term appearing in a document</li>
      <li><strong>topic</strong>:multinomial distribution over terms representing some concept</li>
      <li><strong>document</strong>: one piece of text, corresponding to one row in the input data</li>
    </ol>

    <br>






    <h4>
      Latent Dirichlet Allocation (LDA)
    </h4>
    <p>
      <strong>Latent Dirichlet Allocation (LDA)</strong> is a statistical model that helps produce meaningful topics
      that humans can relate to. It assumes that topics are probability distributions over words, and documents are
      distributions over topics and that topics use only a limited number of terms frequently.
    </p>

    <ul>
      <li><strong>k</strong>: number of topics (= number of clusters)</li>
      <li><strong>maxIter</strong>: number of iterations</li>
      <li><strong>featuresCol</strong>: a collection of documents as input data. Feature transformers such as
        <strong>Tokenizer</strong> and <strong>CountVectorizer</strong> are used to convert text to word count vectors
        as input data.
      </li>
    </ul>
    <br>

    <h4>
      Topic Modeling Pipeline
    </h4>
    <p>
      We proceed with 15 topics, top 10 words per topic using the cleaned documents as input data. The <a
        href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Topic/TopicModeling_submissions.ipynb">notebook</a>
      contains the LDA pipeline applied to the submissions and comments data. The data from two sources are stacked
      using <mark>union</mark> command to provide comprehensive topic modeling on every posts related to RU Conflict in
      the Reddit dataset.
    </p>

    <!-- IMAGE: LDA PIPELINE -->
    <div class="row py-5">
      <div class="col-md-12">
        <div class="card p-0" style="border: none">
          <img src="img/NLP/pipeline.png" class="card-img-top" alt="...">
          <div class="card-body">
            <p style="font-weight: lighter; text-align: center;"><strong>FIGURE 3 </strong>LDA Pipeline</p>
          </div>
        </div>
      </div>
    </div>
    <!-- IMAGE END -->

    <p>
      The <strong>DocumentAssembler</strong> transforms the input data to annotation format so that Spark can use it as
      input data - <mark>DOCUMENT</mark>. The <strong>Tokenizer</strong> splits lines in document into words -
      <mark>TOKEN</mark>. Finally, the Finisher transforms the annotation format of Spark NLP to a "human-readable"
      format. Normalizer (lowercasing), Lemmatizer, and StopWordsCleaners are skipped in this pipeline since they are
      already processed in the Data Cleaning step. The <strong>CountVectorizer</strong> is used to count the frequency
      of the each term in the document and provide input data for the LDA model. (<mark>featuresCol</mark> vector)


    </p>
    <p style="font-weight: lighter; text-align: left;">Reference: <a
        href="https://medium.com/trustyou-engineering/topic-modelling-with-pyspark-and-spark-nlp-a99d063f1a6e">Topic
        Modelling with PySpark and Spark NLP</a> - Maria obedkova</p>
    <br>
    <p>
      The table below summarizes the result 15 topics and top 10 words per each topic.
    </p>




    <!--TOPIC MODELING SUMMARIZATION TABLE-->
    <table class="table table-bordered table-hover table-condensed">
      <thead style="text-align: center">
        <tr>
          <th title="Field #1" style="width: 10%">Topic #</th>
          <th title="Field #2" style="width: 45%">Topic Words - Submissions</th>
          <th title="Field #2" style="width: 45%">Topic Words - Comments</th>
        </tr>
      </thead>
      <tbody style="text-align: center">
        <tr>
          <td>1</td>
          <td>[tank, force, kharkiv, movie, military, fire, farmer, soldier, kherson, destroy]</td>
          <td>[people, city, vote, crimea, putin, territory, state, country, force, belarus]</td>
        </tr>
        <tr>
          <td>2</td>
          <td>[day, mariupol, crime, putin, soldier, obama, invasion, military, drone, news]</td>
          <td>[fuck, shit, love, hell, lol, lmao, think, fake, guy, holy]</td>
        </tr>
        <tr>
          <td>3</td>
          <td>[force, putin, people, soldier, military, fight, kyiv, video, destroy, make]</td>
          <td>[call, word, true, point, good, haha, game, putin, speak, man]</td>
        </tr>
        <tr>
          <td>4</td>
          <td>[city, shirt, force, riot, card, military, fest, chinese, mariupol, people]</td>
          <td>[people, soldier, kill, good, die, man, fight, hope, putin, dead]</td>
        </tr>
        <tr>
          <td>5</td>
          <td>[army, musk, elon, destroy, starlink, gas, gazprom, anonymous, putin, church]</td>
          <td>[orc, meme, low, effort, high, sunflower, send, supportive, opinion, seed]</td>
        </tr>
        <tr>
          <td>6</td>
          <td>[putin, discord, kyiv, people, flag, tank, aid, fighter, bomb, poland]</td>
          <td>[mod, rule, information, message, reddit, issue, vital, remove, mail, muted]</td>
        </tr>
        <tr>
          <td>7</td>
          <td>[nance, people, malcolm, day, invasion, conspiracy, side, mother, talk, president]</td>
          <td>[post, video, comment, source, make, read, link, news, bot, question]</td>
        </tr>
        <tr>
          <td>8</td>
          <td>[denazification, nazi, nazism, content, support, make, putin, moderator, reddit, military]</td>
          <td>[people, make, putin, country, time, nato, military, world, thing, year]</td>
        </tr>
        <tr>
          <td>9</td>
          <td>[putin, president, zelensky, nuclear, plant, bayraktar, island, indian, win, power]</td>
          <td>[special, operation, translation, putin, dick, awesome, pretty, ah, start, suck]</td>
        </tr>
        <tr>
          <td>10</td>
          <td>[company, support, business, suspend, sanction, bank, military, stop, putin, asset]</td>
          <td>[missile, air, system, drone, china, fly, ship, target, time, fire]</td>
        </tr>
      </tbody>
    </table>
    <p style="font-weight: lighter; text-align: center;"><strong>TABLE 2 </strong>Top 10 topic words processed for 10 Topics<br>
    <a href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Topic/TopicModeling_submissions.ipynb">Topic Modeling code (submissions)</a>
    <a href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Topic/TopicModeling_comments.ipynb">Topic Modeling code (comments)</a></p>
    <!--TOPIC MODELING SUMMARIZATION TABLE-->


    <br>
    <p>
      Topic modeling is a popular technique to analyze the massice amount of textual social media data. It is a efficient tool to summarizing long documents. Some of the findings through the topic modeling includes:
    </p>
    <ul>
      <li><strong>Words related to the war: </strong> The subreddit names used to subset the data included not only the war-specific keywords. However, we can see that topic words related to the 'war' such as military, soldier, and tank, dominates the topic modeling result.</li>
      <li><strong>Geographical information: </strong>Geographical names such as Kyiv (Capital of Ukraine), Mariupol indicates where the war broke out and the country names such as China, Belarus and Poland tell us countries near Russia and Ukraine that were affected by the war.</li>
      <li><strong>Others: </strong>We can find topics that people talk about such as the war strategies Russia takes. Starlink, gas, nuclear plant, power indicates that people are interested in Russia's attack on the major infrastructures in Ukraine.</li> 
    </ul>

    <p>
      Topics found from the LDA model can be later used to label the documents. In <b>Figure 4</b> shows the change of topics of more interest in Reddit over time. The figures are drawn by first tagging the documents using the topic words and then calculating daily proportions. This shows that the topic model can be used transform the textual analysis to classification problems.
    </p>
    


        <!-- IMAGE: SUBMISSIONS TOPIC MODELING TIME-SERIES -->
        <div class="row py-3">
          <div class="col-md-12">
            <div class="card p-0" style="border: none">
              <img src="img/NLP/TM-submissions-timeseries.png" class="card-img-top" alt="...">
              <img src="img/NLP/TM-comments-timeseries.png" class="card-img-top" alt="...">
              <div class="card-body">
                <p style="font-weight: lighter; text-align: center;"><strong>FIGURE 4 </strong>Time-series plot of topics proportion in the Reddit submissions (top) and comments (bottom)<br>
                <a href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Topic/LDA_Timeseries.ipynb">LDA time-series code</a></p>
              </div>
            </div>
          </div>
        </div>
        <!-- IMAGE END -->











    <br>
    <hr>
    <h4>Q2. (NLP) What are different languages other than English that can be analyzed in the Dataset? (language
      detection) Xinlu</h4>
    <p>
      Although it is easy to assume that most of the Reddit content is in English, based on the chosen topics, we target
      English, Ukrainian, and Russian as the languages of interest. To categorize the submission records by language, we
      use Spark NLP pre-trained language detection model <b>detect_language_375</b>. We obtain the prediction confidence
      toward these three languages for each submission and comment content. With the confidence values, we can define
      dummy variables for three languages by any desired bar. For the NLP part of our project, we subset our data by
      their language with 80% confidence. <mark>Figure 5 shows how the volumes of submissions in different languages
        change over time</mark>.
      We conduct our common word analysis using PySpark SQL functions, following the
      process of tokenizing, aggregating by vocabulary, counting, and sorting. We obtain the TF-IDF scores for our
      vocabularies using PySpark machine learning feature algorithms. The extraction and transformation tools include
      <b>Tokenizer</b>, <b>HashingTF</b>, <b>IDF</b>. We map the resulting TF-IDF score to words by user-defined
      functions under the PySpark SQL environment. Since we are dealing with foreign languages, we also utilize Spark
      NLP pre-trained pipeline <b>translate_ru_en</b> and <b>translate_uk_en</b>, enabling translation from Russian and
      Ukrainian to English, respectively. When we only need the translation for word tokens, we use the pipelines start
      with document assembler, followed by the Spark Neural Machine Translation framework <b>Marian</b> models
      <b>opus_mt_ru_en</b> and <b>opus_mt_uk_en</b> respectively. The results we obtain give us insights into how the
      focus of the discussion in different languages varies from each other. However, since there is a significant gap
      between the volume of records in English and the volume of records in Russian and Ukrainian, we will not include
      records in these languages in our further explorations.
    </p>

    <div class="col-md-12">
      <div class="card p-0" style="border: none">
        <img src="img/EDA/submission_count_languages.png" class="card-img-top" alt="...">
        <div class="card-body">
          <p style="font-weight: lighter; text-align: center;"><b>FIGURE 5 </b>Volumes of submissions in English,
            Ukrainian, and
            Russian over the observation period.<a
              href="https://github.com/gu-anly502/fall-2022-project-eda-adb-project-group-23/blob/main/visualize_code/language-timeseries-line-chart.ipynb">Visualization
              Code</a>.</p>

        </div>
      </div>
    </div>

    <br>
    <hr>
    <h4>Q3. Which topics/kinds of submissions/comments are more popular?</h4>

    <p>
      Applying the TF-IDF method to our text data gives us more insight into online discussions. With the <b>pyspark</b>
      machine learning features and annotators, we feed our cleaned text data through the tokenizer. And then conduct
      hashing term frequency transformation for the tokenized column. HashingTF enables dimensionality reduction to the
      dataset, which is very helpful when working on large-sized data in a distributive manner. We then compute the
      inversed document frequency for each TF vector corresponding to the text records. By extracting function
      properties and annotator returns, we map the TF-IDF score back to the textual word tokens and sort them to find
      the
      most important words. Please refer to <a
        href="https://github.com/gu-anly502/fall-2022-project-eda-adb-project-group-23/TFIDF.ipynb">this notebook</a>
      for calculating the TF-IDF scores.
    </p>
    <p>
      TF-IDF stands for term frequency-inverse document frequency. It is a statistical measure that evaluates how
      relevant a words is to a document in a collection of document.
    </p>
    <p>
      The TF <b>term frequency</b> measures how many times one instance of word appears in the a document over the
      length of the document. In our case, how many time one word token appears in one comment/submission text body over
      the length of the comment/submission.
    </p>
    <center>
      <p>
        \(TF = \frac{count\ of\ the\ word\ in\ document}{number\ of\ words\ in\ document}\)
      </p>
    </center>
    <p>
      The IDF <b>inverse document frequency</b> measures how common or rare one instance of word is in the entire
      document set.
      In our case, how common or rare a word token is over the whold subsets of comments or submissions texts. The small
      the IDF is
      the more common a word is. The IDF essentailly help us eliminate the interference of words like <i>Ukrainian</i>
      and <i>Russian</i> when trying to extract important words.
    </p>
    <center>
      <p>
        \(IDF (inversed\ document\ frequency) = \log \frac{total\ number\ of\ documents}{number\ of\ documents\
        containing\ the\ word}\)
      </p>
    </center>
    <p>
      The TF-IDF score is calculated for every unique word token appears in the text body of our dataset. The higher the
      score is, the more critical the word is.
    </p>

    <center>
      <p>
        \(TF-IDF =\ TF \times IDF\)
      </p>
    </center>

    <p>
      TF-IDF helps us discard the dominance of words like country names and wars. The critical words give us different
      perspectives of the discussion. The word <i>children</i> appeares as one of the most important word in Russian
      submissions,
      shows us that peopel are paying attention to the future generation during a hard time. We can also see political
      or geometrical representations like <i>European, German, and
        Belarus</i>. Words like <i>brigade</i>, <i> combat</i>, and </i> front</i> imply more detailed descriptions and
      discussion going on in the military-related discussion. The nickname "Dr. Eisenfaust." for the Mayer of Kyiv
      brings up a new political figure other than Putin. Instead of nouns, more adjectives appearing as important words
      bring out the discussion nature of Reddit.
    </p>

    <br>

    <div class="table-responsive">
      <table class="table">
        <tr>
          <th>Language</th>
          <th>Reddit Subset</th>
          <th>Top 10 common words by word counts</th>
          <th>Top 10 important words by TF-IDF</th>
        </tr>
        <tr>
          <th rowspan="2" style="vertical-align: middle;">English</th>
          <th style="vertical-align: middle;">submission</th>
          <td><i>ukraine</i>, <i>russian</i>, <i>russia</i>, <i>ukrainian</i>, <i>war</i>, <i>putin</i>, <i>people</i>,
            <i>forces</i>, <i>military</i>, <i>russians</i>
          </td>
          <td><i>european</i>, <i>german</i>, <i>full</i>, <i>man</i>, <i>belarus</i>, <i>combat</i>, <i>avoided</i>,
            <i>left</i>, <i>brigade</i>, <i>front</i>
          </td>
        </tr>
        <tr>
          <th style="vertical-align: middle;">comment</th>
          <td><i>russia</i>, <i>ukraine</i>, <i>russian</i>, <i>war</i>, <i>people</i>, <i>putin</i>, <i>russians</i>,
            <i>ukrainian</i>, <i>time</i>, <i>good</i>
          </td>
          <td><i>hypercompetence</i>, <i>yourse</i>, <i>irepepctive</i>, <i>feeeeeeeelings</i>, <i>favorably</i>,
            <i>eisenfaust</i>, <i>cowy</i>, <i>trackers</i>, <i>correctlynused</i>, <i>isayevich</i>
          </td>
        </tr>
        <tr>
          <th rowspan="2" style="vertical-align: middle;">Russian</th>
          <th style="vertical-align: middle;">submission</th>
          <td><i>это(This is)</i>, <i>украины(Ukraine)</i>, <i>россии(Russia)</i>, <i>украине(Ukraine)</i>,
            <i>рф(Russia)</i>, <i>войны(War)</i>, <i>просто(simply)</i>, <i>против(against)</i>,
            <i>видео(video)</i>, <i>очень(Very much)</i>
          </td>
          <td><i>других(Other)</i>, <i>работает(It's working)</i>, <i>свои(Their)</i>, <i>такие(such)</i>,
            <i>города(City)</i>, <i>день(day)</i>, <i>помощи(Help)</i>, <i>вся(all)</i>,
            <i>детей(Children)</i>, <i>лишь(only)</i>
          </td>
        </tr>
        <tr>
          <th style="vertical-align: middle;">comment</th>
          <td><i>это(This is)</i>, <i>просто(simply)</i>, <i>всё(all)</i>, <i>россии(Russia)</i>,
            <i>украине(Ukraine)</i>, <i>очень(Very much)</i>, <i>которые(That)</i>, <i>украины(Ukraine)</i>,
            <i>люди(people)</i>, <i>лет(Years)</i>
          </td>
          <td><i>начали(Started)</i>, <i>своим(Your)</i>, <i>ситуации(Situation)</i>,
            <i>россияне(Russians)</i>, <i>хочет(Wants)</i>, <i>самом(The)</i>, <i>шмольцы(Schmoltsy)</i>,
            <i>человека(Person)</i>, <i>должен(must)</i>, <i>страна(country)</i>
          </td>
        </tr>
        <tr>
          <th rowspan="2" style="vertical-align: middle;">Ukrainian</th>
          <th style="vertical-align: middle;">submission</th>
          <td><i>України(Ukraine)</i>, <i>Україні(Ukraine)</i>, <i>Україна(Ukraine)</i>, <i>Україну(Ukraine)</i>,
            <i>Росії(Russia)</i>, <i>війни(War)</i>, <i>РФ(RF)</i>, <i>США(United States)</i>, <i>Росія(Russia)</i>,
            <i>the(that)</i>
          </td>
          <td><i>російська(Russian)</i>, <i>військові(Military)</i>, <i>останнім(Last)</i>, <i>дорослих(Adults)</i>,
            <i>дорозі(Road)</i>, <i>думкою(Opinion)</i>, <i>олександра(Alexander)</i>, <i>дізнатися(find out)</i>,
            <i>my(Mi)</i>, <i>дія(action)</i>
          </td>
          </td>
        </tr>
        <tr>
          <th style="vertical-align: middle;">comment</th>
          <td><i>України(Ukraine)</i>, <i>Україні(Ukraine)</i>, <i>людей(People)</i>, <i>має(Has)</i>,
            <i>війни(War)</i>, <i>взагалі(generally)</i>, <i>Україну(Ukraine)</i>, <i>Україна(Ukraine)</i>,
            <i>питання(question)</i>, <i>робити(do)</i>
          </td>
          <td><i>повномасштабному(large-scale)</i>, <i>мови(Language)</i>, <i>маю(Mean)</i>,
            <i>наприклад(For example)</i>, <i>гроші(money)</i>, <i>замінив(Replaced)</i>,
            <i>якісна(Quality)</i>, <i>мова(language)</i>, <i>українців(Ukrainians)</i>, <i>робити(do)</i>
          </td>
        </tr>
      </table>
      <p style="font-weight: lighter; text-align: center;"><strong>TABLE 3 </strong> Common/Important words found from
        applying tf-idf. <a
          href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Text%20Stats/common-words-submission-comment-language.ipynb">Common
          Words
          Code</a> and <a
          href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Text%20Stats/TF-IDF.ipynb">TF-IDF
          Code</a>.</p>
    </div>

    <br>


    <p>
      As we tagged all the submissions and comments by their languages, we split the datasets into English, Russian, and
      Ukrainian since they are part of the focus of our textual analysis.
    </p>
    <p>
      Common words can help us find what has frequently been brought up by people when making comments and posts under
      our selected subreddits. Inside the spark environment, we explode the body of the comments and submissions into
      single words. By aggregating all the vocabularies by their counts, we are able to sort them to find the most
      common words over our time interval of interest. Please refer to <a
        href="https://common_words_submission_comment_language.ipynb">this
        notebook</a> for the code extracting common words.
    </p>
    <p>
      For the comments and submissions in English, terms related to <i>war</i> appear naturally. The top few are the
      cognate words of countries, which come with the territory of the subreddits we selected. While we may also
      interpret part of the counts for <i>russian</i> and <i>ukrainian</i> as referring to the people. Combined with the
      fact that the word <i>people</i> is one of the most common words, we can find the humane and compassionate nature
      of the discussion. Moreover, among all the political leaders involved in the conflict, Putin gets most of the
      attention.
    </p>
    <p>
      Beyond the top ten words we listed, NATO and the US are the two other political entities that appear the most in
      the discussion. We also find curse words appear in high frequency, implying an extremely sentimental tone among
      the posts.
    </p>
    <p>
      Except the top ten we listed, the common words for posts in Russian and Ukrainian also include words like US
      dollars and populations, which could
      suggest different angles of discussions like finance and geopolitics. Words like <i>Green</i> and <i>Babchenko</i>
      possibly represent political entries and figures that are not familiar to foreign people outside of the
      confliction area. While again, we can find words that describe <i>peace</i> and <i>human beings</i>.
    </p>


    <br>
    <hr>

    <h4>Q4. How is the sentiment in Reddit posts over time related to Russian-Ukrainian Conflict?</h4>

    <p>
      Sentiment analysis casts a view on how people react to the topic of RU conflict.
      By applying the sentiment analysis pipeline and further processing, we obtain the sentiment scores
      for each reddit for both submissions and comments.
    </p>
    <p><strong>Creation of Sentiment-Related Attributes & Stats:</strong></p>
    <ul>
      <li>
        We use the pre-trained pipeline of <strong>analyze_sentimentdl_use_twitter</strong>
        provided by <strong>John Snow Labs</strong>, since that's the most suitable
        medium-size pipeline for our Reddit case.
      </li>
      <li>
        While this pipeline outputs four kinds of sentiment results:
        'positive', 'negative', 'neutral', and 'None', we create a new
        'sentiment_score' column, which is 1.0 when positive and 0.0 otherwise,
        to put an emphasize on the positive sentiments.
      </li>
      <li>
        Then we aggregate the average sentiment scores
        as well as the numbers of positive and negative reddits into daily timeseries.
        Please refer to <a
          href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/tree/master/code/Sentiment">these
          notebooks</a>
        for the code we use for generating the sentiment-related attributes & statistics.
      </li>
    </ul>
    <p>
      <b>Table 4</b> shows a summary of the generated sentiment scores.
    </p>
    <div class="table-responsive">
      <table class="table table-bordered table-hover table-condensed">
        <tr>
          <td>Sentiment Score Stats</td>
          <td>Average</td>
          <td>Minimum</td>
          <td>Maximum</td>
          <td>Std</td>
          <td>Q1</td>
          <td>Q3</td>
        </tr>
        <tr>
          <td>Submissions</td>
          <td>0.244</td>
          <td>0.086</td>
          <td>0.481</td>
          <td>0.041</td>
          <td>0.220</td>
          <td>0.268</td>
        </tr>
        <tr>
          <td>Comments</td>
          <td>0.344</td>
          <td>0.251</td>
          <td>0.422</td>
          <td>0.028</td>
          <td>0.334</td>
          <td>0.362</td>
        </tr>
      </table>
    </div>
    <p style="font-weight: lighter; text-align: center;"><strong>TABLE 4 </strong> Statistics
      of Sentiment Scores. <a
        href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Sentiment/Sentiment%20Summary%20Tables.ipynb">Visualization
        Code</a>.</p>
    <p>From <b>Table 4</b>, we can see that:</p>
    <ul>
      <li>The dates for maximum/minimum sentiment scores in Submissions and Comments are similar.</li>
      <li>Submission scores have larger fluctuations and lower sentiment scores overall than comments.</li>
    </ul>
    <p>Each Reddit post also has a score for itself. The score is simply the number of upvotes minus the number of
      downvotes.<b>Table 5</b> shows a summary of Reddit scores.</p>
    <div class="table-responsive">
      <table class="table table-bordered table-hover table-condensed">
        <tr>
          <td>Score Stats</td>
          <td>Counts</td>
          <td>Average</td>
          <td>Range</td>
          <td>IQR</td>
          <td>Std</td>
          <td>Skewness</td>
        </tr>
        <tr>
          <td>Positive Submissions</td>
          <td>66445</td>
          <td>296.23</td>
          <td>0~108426</td>
          <td>109</td>
          <td>1741.93</td>
          <td>22.05</td>
        </tr>
        <tr>
          <td>Negative Submissions</td>
          <td>192527</td>
          <td>313.31</td>
          <td>0~195763</td>
          <td>168</td>
          <td>1554.17</td>
          <td>29.21</td>
        </tr>
        <tr>
          <td>Positive Comments</td>
          <td>2375428</td>
          <td>9.51</td>
          <td>-618~8607</td>
          <td>5</td>
          <td>47.40</td>
          <td>33.37</td>
        </tr>
        <tr>
          <td>Negative Comments</td>
          <td>4144561</td>
          <td>10.87</td>
          <td>-657~9421</td>
          <td>6</td>
          <td>52.92</td>
          <td>33.31</td>
        </tr>
      </table>
    </div>
    <p style="font-weight: lighter; text-align: center;"><strong>TABLE 5 </strong> Statistics of
      Scores in Positive/Negative Sentiments. <a
        href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Sentiment/Sentiment%20Summary%20Tables.ipynb">Visualization
        Code</a>.</p>

    <p>From the score summary table, we can see that reddits with negative sentiment tend to have higher Reddit scores.
      To verify this numerical hypothesis using two-sample t-tests:</p>
    <ul>
      <li>Two-sample t-test for submission scores in 2 sentiments:</li>
      <code>statistic = -2.36</code>
      <br>
      <code>pvalue = 0.0179</code>

      <li>Two-sample t-test for comment scores in 2 sentiments:</li>
      <code>statistic = -32.64</code>
      <br>
      <code>pvalue = 1.012e-233</code>
    </ul>
    <p>The results lead to our conclusion: </p>
    <p>Reddits with positive sentiments tend to have
      lower scores than those with negative sentiments,
      for both submissions and comments.</p>
    <p>We also created two keyword generated dummy variables to separate Reddit posts with Russia-related content such
      as "Putin", "Russia", etc, from Ukraine-related content such as "Zelensky", "Ukraine", etc. From <b>Table 6</b>,
      we find that Ukraine-related content has more positive sentiment posts and less negative sentiment posts as
      compared to Russian-related content.</p>
    <div class="table-responsive">
      <table class="table table-bordered table-hover table-condensed">
        <thead>
          <tr>
            <th title="Field #1">Sentiment</th>
            <th title="Field #2">Positive</th>
            <th title="Field #3">Negative</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Russia</td>
            <td align="right">9%</td>
            <td align="right">40%</td>
          </tr>
          <tr>
            <td>Ukraine</td>
            <td align="right">15%</td>
            <td align="right">36%</td>
          </tr>
        </tbody>
      </table>
    </div>
    <p style="font-weight: lighter; text-align: center;"><strong>TABLE 6 </strong> Positive/Negative Sentiments by
      Keywords. <a
        href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Topic/LDA_Timeseries.ipynb">Visualization
        Code</a>.</p>
    <div class="row py-4">
      <div class="col-md-12">
        <div class="card p-0" style="border: none">
          <img src="img/NLP/sentiment_score_plot.jpg" class="card-img-top" alt="...">
          <div class="card-body">
            <p style="font-weight: lighter; text-align: center;"><strong>FIGURE 6 </strong>
              Sentiment Score Time Series. Trend is the 10-day moving average.<a
                href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Sentiment/Sentiment%20Line%20Plot.ipynb">Visualization
                Code</a>.</p>
          </div>
        </div>
      </div>
    </div>
    <p>
      <b>Figure 6</b> plots the aggregated daily average sentiment scores for comments and submissions. Both charts had
      a steep upward trend at the end of February. Compared to submission sentiment score's stale trend, comment
      sentiment is getting more and more positive. We think it makes sense that comments are usually more emotional than
      submissions, especially at the beginning of the conflict. That's why we see a large dip at the beginning of the
      comment sentiment chart(right).
    </p>
    <div class="row py-3">
      <div class="col-md-12">
        <div class="card p-0" style="border: none">
          <img src="img/NLP/RU_conflict_timeline.jpg" class="card-img-top" alt="...">
          <div class="card-body">
            <p style="font-weight: lighter; text-align: center;"><strong>FIGURE 7 </strong>Russia-Ukraine Conflict
              Event Timeline.<a
                href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Sentiment/timeline.ipynb">Visualization
                Code</a>.</p>
          </div>
        </div>
      </div>
    </div>
    <p><b>Figure 7</b> plots the event line of Russia-Ukraine Conflict.</p>
    <p>
      In the <strong>Prelude</strong> phase, contradictions were fermented between Russia and Ukraine on many
      issues, among which the most significant one is whether Ukraine should enter NATO.
    </p>
    <p>
      Once the prelude ended and the war began in the end of February,
      reddits on the RU topic exploded correspondingly,
      both for the positive ones and negative ones. A large number of submissions and comments
      on this topic were posted in a short time.
    </p>

    <p>
      In phase 1, <strong>Invasion of Ukraine</strong>, Russia launched the military invasion of Ukraine.
      The daily average sentiment scores of
      submissions experienced a decreasing phase, which reflects the fermentation of negative
      emotions of anxiety, disorder and even panic. Meanwhile, the sentiment scores of comments fluctuated
      largely due to the uncertainties of the war.
    </p>

    <p>
      In phase 2, <strong>Southeastern Front</strong>, the area of heavy fighting
      shifted to the south and east of Ukraine.
      The number of submissions decreased largely, which is the common
      case for most news topics. The sentiment
      scores of comments were fluctuating largely during this period, which reflects the emotion of
      the disturbed people who still paid close attention to the conflict.
    </p>

    <p>
      In phase 3, <strong>Ukrainian Counteroffensives</strong>, Ukrainian forces retook substantial
      ground during counteroffensives in the south and east, continuing to the present day. The number
      of both positive and negative posted reddits became stabler than previous. Sentiment scores of
      comments started to increase in this phase. Most people no longer worried about the burst of
      the potential 'Third World War'.
    </p>

    <br>
    <hr>


    <h4>Q6. Is there difference in the sentiments among different ages?
    </h4>
    <p>
      Our original plan was to explore the difference in sentiment between under_18 and over_18 Redditors. However, we
      decide not to move forward with this business question, since the “over_18” column in Reddit is highly unreliable.
      Upon our investigation, “over_18” turns out to be a default choice when signing up for a Reddit account, and it
      doesn't have any verification procedure. In our dataset, more than 90% of the Redditors are under 18 and we find
      it very unlikely.
    </p>
    <br>
    <hr>



    <h4>Q8.(External Data) How does each topic correlate to the commodity price changes?</h4>

    <p>
      It is a common practice to use correlation as preliminary analysis to test simple relationships between variables.
      <b>Figure 8</b> plots the Pearson correlations between all the timeseries we collected during the 8-month period.
    </p>

    <div class="row py-3">
      <div class="col-md-12">
        <div class="card p-0" style="border: none">
          <img src="img/NLP/correlations.png" class="card-img-top" alt="...">
          <div class="card-body">
            <p style="font-weight: lighter; text-align: center;"><strong>FIGURE 8 </strong>Correlations between topics,
              sentiments, and commodity returns.<a
                href="https://github.com/gu-anly502/fall-2022-reddit-big-data-project-project-group-23/blob/master/code/Topic/Correlations.ipynb">Visualization
                Code</a>.</p>
          </div>
        </div>
      </div>
    </div>
    <p>
      The highlighting areas concentrate on the top-left and bottom-right corners,
      indicating there is strong
      relationship within
      commodity returns and reddit textual features, but not between them. Since our goal is to use reddit to predict
      commodity returns, a weak correlation between predictor and target implies we will need better features and a
      better-than-linear model.
    </p>
    <br>

    <hr>
    <br>
  </div> <!-- container -->

  <footer class="blog-footer">
    <p>
      <a href="#">Back to top</a>
    </p>
  </footer>

</body>

</html>
